# CODE BLOCK FOR JUPYTER NOTEBOOK

import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, r2_score

# 1. Load Data (Assumes train.csv is in the same folder)
df = pd.read_csv('train.csv')

# 2. Feature Selection
features = ['OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt', 'Neighborhood']
target = 'SalePrice'
data = df[features + [target]].copy()

# 3. Preprocessing (Fill Missing Values)
# Numeric: Fill with Median
num_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']
data[num_features] = data[num_features].fillna(data[num_features].median())

# Categorical: Fill with Mode
cat_features = ['Neighborhood']
data[cat_features] = data[cat_features].fillna(data[cat_features].mode().iloc[0])

# 4. Define X and y
X = data[features]
y = data[target]

# 5. Pipeline Setup (Encoding + Model)
# We use a pipeline to handle the categorical encoding automatically
preprocessor = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', num_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
    ])

model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
])

# 6. Train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model.fit(X_train, y_train)

# 7. Evaluate
print(f"R2 Score: {r2_score(y_test, model.predict(X_test)):.4f}")

# 8. Save Model
with open('house_price_model.pkl', 'wb') as f:
    pickle.dump(model, f)
    
print("Model saved as house_price_model.pkl")
